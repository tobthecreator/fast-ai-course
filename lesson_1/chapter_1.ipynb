{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6456680f-ae32-4685-b0c4-c2e19f1e9131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastbook\n",
    "\n",
    "fastbook.setup_book()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "499bbc1c-9b58-4055-b9d5-f343d61fa429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastbook import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b72627d1-4801-400d-9da1-15f7b8082991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='811712512' class='' max='811706944' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [811712512/811706944 00:33&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /Users/tylerobriant/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 83.3M/83.3M [00:01<00:00, 52.7MB/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.177117</td>\n",
       "      <td>0.028924</td>\n",
       "      <td>0.011502</td>\n",
       "      <td>01:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.040168</td>\n",
       "      <td>0.023071</td>\n",
       "      <td>0.006089</td>\n",
       "      <td>01:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#id first_training\n",
    "#caption Results from the first training\n",
    "# CLICK ME\n",
    "from fastai.vision.all import *\n",
    "path = untar_data(URLs.PETS)/'images'\n",
    "\n",
    "def is_cat(x): return x[0].isupper()\n",
    "dls = ImageDataLoaders.from_name_func(\n",
    "    path, get_image_files(path), valid_pct=0.2, seed=42,\n",
    "    label_func=is_cat, item_tfms=Resize(224))\n",
    "\n",
    "learn = vision_learner(dls, resnet34, metrics=error_rate)\n",
    "learn.fine_tune(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ab61cf-4cc7-41a6-9906-376d4f4f0b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99436391-6490-4cf7-9e3e-97fd4446fbf4",
   "metadata": {},
   "source": [
    "# questions\n",
    "\n",
    "1. F / ~ / F / F\n",
    "2. recommendation systems for sure, in certain domains probably cancer recognition, or tumor spotting.  idk. let's ask gpt.  image and video recognition.  NLP.  speech recognition and generation. predictive analytics.\n",
    "3. perceptron i believe\n",
    "4. foobar\n",
    "5. that compute was going to be very costly and they needed a lot more data than we had at the time\n",
    "6. graphics processing unit\n",
    "7. 2, it's functionally just a big terminal\n",
    "8. foobar\n",
    "9. foobar\n",
    "10. few ways to do it.  it's not that the computer cannot \"see\" the image, the same data is accessible to NN.  but you need to go and and parse those things yourself, with handwritten code.  you need to be very explicit with the directions you give, the modeling you do, etc.  with NN and ML, the neural net learns those things by itself.\n",
    "11. the weight assignment is the variable assigned to each neuron in the neural net.  weights are kind of like the settings of the neural net, which we can transfer between models.\n",
    "12. i would think they're just weights. but you could also call them parameters. in comp sci they're definitely parameters\n",
    "13. foobar\n",
    "14. well... it's not that it's hard to see the output of the decision or the materials it uses.  it's that the model is making some multidimensional plane and navigating it based on the weights and inputs.  that statistical plane represents why the problem was hard to hardcode in the first place.  there is no direct translation to standard code that can be done here with our current technology.\n",
    "15. universal approximation theorem\n",
    "16. you need a lot of labeled data :), or a sufficient amount of labeled data i should say\n",
    "17. in general there are two types of feedback loops. positive and negative. you want negative feedback loops that tend towards accuracy.  positive feedback loops amplify signals or add to them.  a positive feedback loop in policing would look like an algorithm trained to predict crimes based on arrest records, which really just tells you where you're going to be arresting folks.  this can lead to policing models heavily weighted to where arrests are, which may not be where crimes actually occur\n",
    "18. no\n",
    "19. classification is \"this is a cat\", regression is \"i think the next number will be 12\"\n",
    "20. you validation set is part of your training data.  you use your training data and develop your model.  then you can run your validation set on it and get your accuracy numbers.  your test set is the actual data you might see in the real world\n",
    "21. probably not work lol\n",
    "22. ummmm, that depends on that dataset, right? if random sampling can still provide you with a realistic looking validation set that will resemble your test set, then sure.  if it doesn't, you'll need to sample it in other ways.\n",
    "23. overfitting occurs when your model spends too much time being trained on the same dataset.  it knows that dataset perfectly and there is not a lot of room for flexibility anymore.  it can perfectly predict everything you throw at it, until you throw something it's never seen before.  it's not guaranteed to fail, but its accuracy will suffer.\n",
    "24. loss is used for adjusting weights. metrics are for us to measure quality.  sometimes these things overlap.\n",
    "25. pretrained models are essentially opensource code.  if we have something that works well, share it.  speed everyone else up.\n",
    "26. the head of the model is what you've put on the body of another pretrained model.\n",
    "27. a lot of edges. then a lot of features of those edges. also colors and gradients.\n",
    "28. no. useful for things you can shape like a photo as well\n",
    "29. the architecture is the model. this guy is being pedantic\n",
    "30. a model for recognizing the content of an image and what individual segments are\n",
    "31. parameters about parameters, higher level choices governing the meaning of weights.  this is stuff like the layout of nodes, learning rates, data strategies, etc. nerd talk for design choices\n",
    "32. don't fuck up :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
